{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Модули Обновлено =====\r\n",
    "\r\n",
    "from grid.model.navigation.objectinspection import ObjectInspect\r\n",
    "from grid.model.navigation.visualservoing import VisualServoing\r\n",
    "from grid.model.perception.detection.rt_detr import RT_DETR\r\n",
    "\r\n",
    "import airgen\r\n",
    "import numpy as np\r\n",
    "import rerun as rr\r\n",
    "import cv2\r\n",
    "import time\r\n",
    "from math import cos, sin, pi\r\n",
    "\r\n",
    "# Инициализация моделей\r\n",
    "nav_inspect = ObjectInspect()\r\n",
    "nav_visualservoing = VisualServoing()\r\n",
    "detection_rt_detr = RT_DETR(use_local=True)  # Инициализация модели детекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Подключение к дрону и взлёт =====\r\n",
    "\r\n",
    "client = airgen.MultirotorClient()\r\n",
    "client.confirmConnection()\r\n",
    "client.enableApiControl(True)\r\n",
    "client.armDisarm(True)\r\n",
    "# ===== Взлет дрона =====\r\n",
    "#client.takeoffAsync().join()\r\n",
    "\r\n",
    "# ===== Посадка дрона =====\r\n",
    "# client.landAsync().join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e779e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cameras:\n",
      "PlayerCameraManager_2147482445\n",
      "CameraManagerActor\n",
      "ExternalCamera\n",
      "BP_PIPCamera_C_2147482405\n",
      "BP_PIPCamera_C_2147482393\n",
      "BP_PIPCamera_C_2147482381\n",
      "BP_PIPCamera_C_2147482369\n",
      "BP_PIPCamera_C_2147482357\n"
     ]
    }
   ],
   "source": [
    "# ===== Создание клиента сцены =====\r\n",
    "\r\n",
    "scene_client = airgen.VehicleClient()\r\n",
    "scene_objects = scene_client.simListSceneObjects()\r\n",
    "cameras = [obj for obj in scene_objects if 'camera' in obj.lower()]\r\n",
    "\r\n",
    "print(\"Available cameras:\")\r\n",
    "for camera in cameras:\r\n",
    "    print(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Получение данных LiDAR + визуализация =====\r\n",
    "\r\n",
    "lidar_data = client.getLidarData()\r\n",
    "points = np.array(lidar_data.point_cloud, dtype=np.float32).reshape(-1, 3)\r\n",
    "rr.log('lidar/points', rr.Points3D(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65720106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Получение и логирование изображения с камеры =====\r\n",
    "\r\n",
    "image_data, _ = client.getImages(\"front_center\", [airgen.ImageType.Scene])[0]\r\n",
    "rgb_image = cv2.cvtColor(image_data, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136eb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Получение и логирование GPS =====\r\n",
    "\r\n",
    "gps_data = client.getGpsData()\r\n",
    "geo = gps_data.gnss.geo_point\r\n",
    "gps_position = np.array([[geo.latitude, geo.longitude, geo.altitude]], dtype=np.float32)\r\n",
    "rr.log(\"drone/gps\", rr.Points3D(gps_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aeca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ Объекты не обнаружены.\n"
     ]
    }
   ],
   "source": [
    "from grid.model.perception.depth.metric3d import Metric3D\r\n",
    "\r\n",
    "# ===== Инициализация =====\r\n",
    "depth_model = Metric3D()\r\n",
    "depth_map = depth_model.run(rgb_image)\r\n",
    "\r\n",
    "result = detection_rt_detr.run(input=rgb_image.copy(), confidence_threshold=0.3)\r\n",
    "\r\n",
    "if isinstance(result, dict) and 'boxes' in result:\r\n",
    "    filtered_boxes = []\r\n",
    "    filtered_labels = []\r\n",
    "    filtered_distances = []\r\n",
    "\r\n",
    "    ignore_labels = [\"grass\", \"floor\", \"ground\", \"road\", \"terrain\"]\r\n",
    "    min_distance = 2\r\n",
    "    max_distance = 20\r\n",
    "\r\n",
    "    # Центр изображения — точка откуда \"исходит БПЛА\"\r\n",
    "    img_center = (rgb_image.shape[1] // 2, rgb_image.shape[0] // 2)\r\n",
    "\r\n",
    "    image_with_lines = rgb_image.copy()\r\n",
    "\r\n",
    "    for box, label in zip(result[\"boxes\"], result[\"labels\"]):\r\n",
    "        x, y, w, h = map(int, box)\r\n",
    "        cx = x + w // 2\r\n",
    "        cy = y + h // 2\r\n",
    "\r\n",
    "        if 0 <= cy < depth_map.shape[0] and 0 <= cx < depth_map.shape[1]:\r\n",
    "            distance = depth_map[cy, cx]\r\n",
    "\r\n",
    "            if (min_distance <= distance <= max_distance) and (label.lower() not in ignore_labels):\r\n",
    "                filtered_boxes.append([x, y, w, h])\r\n",
    "                filtered_labels.append(label)\r\n",
    "                filtered_distances.append(distance)\r\n",
    "\r\n",
    "                # ===== Отрисовка линии до объекта =====\r\n",
    "                line_color = (0, 255, 0) if distance > 10 else (0, 255, 255) if distance > 5 else (0, 0, 255)\r\n",
    "                cv2.line(image_with_lines, img_center, (cx, cy), line_color, 2)\r\n",
    "\r\n",
    "                # Подпись расстояния у центра объекта\r\n",
    "                cv2.putText(image_with_lines, f\"{distance:.1f}m\", (cx + 5, cy),\r\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, line_color, 2)\r\n",
    "\r\n",
    "    # ===== Отрисовка боксов =====\r\n",
    "    for i, box in enumerate(filtered_boxes):\r\n",
    "        x, y, w, h = box\r\n",
    "        cv2.rectangle(image_with_lines, (x, y), (x + w, y + h), (255, 0, 0), 2)\r\n",
    "        cv2.putText(image_with_lines, filtered_labels[i], (x, y - 10),\r\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\r\n",
    "\r\n",
    "        rr.log(\r\n",
    "            f\"drone/object_{i}\",\r\n",
    "            rr.Boxes2D(np.array([[x, y, w, h]]), labels=[f\"{filtered_labels[i]} - {filtered_distances[i]:.1f}m\"])\r\n",
    "        )\r\n",
    "\r\n",
    "    # ===== Лог финального изображения =====\r\n",
    "    rr.log(\"drone/camera\", rr.Image(image_with_lines))\r\n",
    "\r\n",
    "else:\r\n",
    "    print(\"❗ Объекты не обнаружены.\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f03762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Движение БПЛА: шаблон ====\r\n",
    "\r\n",
    "# Повернуть на определённый угол (по оси Yaw, в градусах)\r\n",
    "# Положительное значение — поворот по часовой, отрицательное — против часовой\r\n",
    "#yaw_angle = 45  # <- Измени это значение для другого угла поворота\r\n",
    "#client.rotateByYawRateAsync(yaw_rate=yaw_angle, duration=2).join()\r\n",
    "\r\n",
    "# Движение вперёд\r\n",
    "#forward_distance = 3  # <- Измени это значение, чтобы задать дальность движения вперёд\r\n",
    "#client.moveByVelocityAsync(vx=1.0, vy=0.0, vz=0.0, duration=forward_distance).join()\r\n",
    "\r\n",
    "# Движение влево (vy > 0) или вправо (vy < 0)\r\n",
    "#side_distance = 3  # <- Измени это значение для расстояния вбок\r\n",
    "#client.moveByVelocityAsync(vx=0.0, vy=1.0, vz=0.0, duration=side_distance).join()\r\n",
    "\r\n",
    "# Примечание:\r\n",
    "# - vx — движение вперёд/назад (м/с), vy — влево/вправо, vz — вверх/вниз\r\n",
    "# - duration — время движения в секундах\r\n",
    "# - можно комбинировать движения, задавая одновременно vx, vy, vz\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbd42a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by DBSCAN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m above_ground \u001b[38;5;241m=\u001b[39m points[points[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.2\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ===== Кластеризация (DBSCAN) =====\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m clustering \u001b[38;5;241m=\u001b[39m \u001b[43mDBSCAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabove_ground\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# кластеризация по X, Y\u001b[39;00m\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# ===== Обработка кластеров =====\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/cluster/_dbscan.py:391\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# DBSCAN.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    365\u001b[0m )\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform DBSCAN clustering from features, or distance matrix.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance of self.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    394\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1130\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1134\u001b[0m         )\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1137\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by DBSCAN."
     ]
    }
   ],
   "source": [
    "#!pip install scikit-learn\r\n",
    "\r\n",
    "from sklearn.cluster import DBSCAN\r\n",
    "import numpy as np\r\n",
    "import rerun as rr\r\n",
    "\r\n",
    "# ===== Получение и подготовка данных LiDAR =====\r\n",
    "lidar_data = client.getLidarData()\r\n",
    "points = np.array(lidar_data.point_cloud, dtype=np.float32).reshape(-1, 3)\r\n",
    "\r\n",
    "# ===== Фильтрация: исключаем \"землю\" (высота < 0.2 м) =====\r\n",
    "above_ground = points[points[:, 2] > 0.2]\r\n",
    "\r\n",
    "# ===== Кластеризация (DBSCAN) =====\r\n",
    "clustering = DBSCAN(eps=1.0, min_samples=10).fit(above_ground[:, :2])  # кластеризация по X, Y\r\n",
    "labels = clustering.labels_\r\n",
    "\r\n",
    "# ===== Обработка кластеров =====\r\n",
    "unique_labels = set(labels)\r\n",
    "object_centers = []\r\n",
    "object_distances = []\r\n",
    "\r\n",
    "for label in unique_labels:\r\n",
    "    if label == -1:\r\n",
    "        continue  # -1 означает шум\r\n",
    "\r\n",
    "    cluster_points = above_ground[labels == label]\r\n",
    "    center = cluster_points.mean(axis=0)\r\n",
    "    distance = np.linalg.norm(center[:2])\r\n",
    "    \r\n",
    "    object_centers.append(center)\r\n",
    "    object_distances.append(distance)\r\n",
    "\r\n",
    "# ===== Логгирование =====\r\n",
    "rr.log(\"lidar/points\", rr.Points3D(points))\r\n",
    "rr.log(\"lidar/objects\", rr.Points3D(np.array(object_centers)))\r\n",
    "\r\n",
    "print(f\"🔎 Обнаружено объектов по LiDAR: {len(object_centers)}\")\r\n",
    "for i, dist in enumerate(object_distances):\r\n",
    "    print(f\" - Объект {i+1}: ~{dist:.1f} м\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Построение и визуализация кругового маршрута =====\r\n",
    "\r\n",
    "lidar_data = client.getLidarData()\r\n",
    "points = np.array(lidar_data.point_cloud, dtype=np.float32).reshape(-1, 3)\r\n",
    "\r\n",
    "# Визуализация\r\n",
    "rr.log('lidar/points', rr.Points3D(points))\r\n",
    "\r\n",
    "# Стартовая точка\r\n",
    "start = client.getMultirotorState().kinematics_estimated.position\r\n",
    "takeoff_alt = -15  # минус = вверх в NED\r\n",
    "center = start\r\n",
    "radius = 10\r\n",
    "steps = 12  # количество точек круга\r\n",
    "\r\n",
    "# Построение круга\r\n",
    "trajectory = []\r\n",
    "for i in range(steps):\r\n",
    "    angle = 2 * pi * (i / steps)\r\n",
    "    x = center.x_val + radius * cos(angle)\r\n",
    "    y = center.y_val + radius * sin(angle)\r\n",
    "    z = takeoff_alt\r\n",
    "    trajectory.append(airgen.Vector3r(x, y, z))\r\n",
    "\r\n",
    "# Возврат к центру\r\n",
    "trajectory.append(airgen.Vector3r(center.x_val, center.y_val, takeoff_alt))\r\n",
    "\r\n",
    "# Визуализация маршрута\r\n",
    "rr.log(\"telemetry/path\", rr.LineStrips3D([[(p.x_val, p.y_val, p.z_val) for p in trajectory]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a59863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Плавное движение по маршруту и посадка =====\r\n",
    "\r\n",
    "lidar_data = client.getLidarData()\r\n",
    "points = np.array(lidar_data.point_cloud, dtype=np.float32).reshape(-1, 3)\r\n",
    "\r\n",
    "# Визуализация\r\n",
    "rr.log('lidar/points', rr.Points3D(points))\r\n",
    "velocity = 3.0  # Плавная скорость\r\n",
    "\r\n",
    "client.moveOnPathAsync(\r\n",
    "    trajectory,\r\n",
    "    velocity,\r\n",
    "    300,\r\n",
    "    airgen.DrivetrainType.ForwardOnly,\r\n",
    "    airgen.YawMode(False, 0),\r\n",
    "    -1, 0\r\n",
    ").join()\r\n",
    "\r\n",
    "# Плавная посадка\r\n",
    "landing_point = airgen.Vector3r(center.x_val, center.y_val, -2)\r\n",
    "client.moveToPositionAsync(landing_point.x_val, landing_point.y_val, landing_point.z_val, 1).join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: winit EventLoopError: os error at /usr/local/cargo/registry/src/index.crates.io-6f17d22bba15001f/winit-0.30.7/src/platform_impl/linux/mod.rs:764: neither WAYLAND_DISPLAY nor WAYLAND_SOCKET nor DISPLAY is set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-05T10:09:45Z WARN  re_sdk_comms::buffered_client] Failed to send message after 3 attempts: Failed to connect to Rerun server at 127.0.0.1:9876: Connection refused (os error 111)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 Обнаружено препятствие на расстоянии ~0.15 м. Остановка.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Миссия завершена. Данные сохранены.\n"
     ]
    }
   ],
   "source": [
    "# ===== Импорты и инициализация =====\r\n",
    "from grid.model.navigation.objectinspection import ObjectInspect\r\n",
    "from grid.model.navigation.visualservoing import VisualServoing\r\n",
    "from grid.model.perception.detection.rt_detr import RT_DETR\r\n",
    "\r\n",
    "import airgen\r\n",
    "import numpy as np\r\n",
    "import rerun as rr\r\n",
    "import cv2\r\n",
    "import time\r\n",
    "from math import cos, sin, pi\r\n",
    "from sklearn.cluster import DBSCAN\r\n",
    "\r\n",
    "# Инициализация rerun\r\n",
    "rr.init(\"bpla_path_lidar_stream\", spawn=True)\r\n",
    "\r\n",
    "# ===== Инициализация моделей и клиента =====\r\n",
    "nav_inspect = ObjectInspect()\r\n",
    "nav_visualservoing = VisualServoing()\r\n",
    "detection_rt_detr = RT_DETR(use_local=True)\r\n",
    "\r\n",
    "client = airgen.MultirotorClient()\r\n",
    "client.confirmConnection()\r\n",
    "client.enableApiControl(True)\r\n",
    "client.armDisarm(True)\r\n",
    "client.takeoffAsync().join()\r\n",
    "\r\n",
    "# ===== Настройка параметров =====\r\n",
    "takeoff_alt = -15  # высота полета\r\n",
    "radius = 10\r\n",
    "steps = 24\r\n",
    "velocity = 2.0\r\n",
    "obstacle_distance_thresh = 2.0  # м\r\n",
    "trajectory = []\r\n",
    "\r\n",
    "# ===== Получение стартовой позиции =====\r\n",
    "state = client.getMultirotorState()\r\n",
    "center = state.kinematics_estimated.position\r\n",
    "\r\n",
    "# ===== Построение круговой траектории =====\r\n",
    "for i in range(steps):\r\n",
    "    angle = 2 * pi * (i / steps)\r\n",
    "    x = center.x_val + radius * cos(angle)\r\n",
    "    y = center.y_val + radius * sin(angle)\r\n",
    "    z = takeoff_alt\r\n",
    "    trajectory.append(airgen.Vector3r(x, y, z))\r\n",
    "\r\n",
    "# Возврат к центру\r\n",
    "trajectory.append(airgen.Vector3r(center.x_val, center.y_val, takeoff_alt))\r\n",
    "\r\n",
    "# ===== Запуск перемещения по пути и потокового анализа =====\r\n",
    "path_log = []\r\n",
    "danger_points = []\r\n",
    "\r\n",
    "for target in trajectory:\r\n",
    "    # Перемещение к следующей точке\r\n",
    "    client.moveToPositionAsync(target.x_val, target.y_val, target.z_val, velocity).join()\r\n",
    "    \r\n",
    "    # Получение текущей позиции\r\n",
    "    current_pos = client.getMultirotorState().kinematics_estimated.position\r\n",
    "    path_log.append([current_pos.x_val, current_pos.y_val, current_pos.z_val])\r\n",
    "    \r\n",
    "    # ===== Получение и обработка LiDAR =====\r\n",
    "    lidar_data = client.getLidarData()\r\n",
    "    points = np.array(lidar_data.point_cloud, dtype=np.float32).reshape(-1, 3)\r\n",
    "    \r\n",
    "    if points.size == 0:\r\n",
    "        continue\r\n",
    "\r\n",
    "    # Фильтрация по высоте (исключаем землю и траву)\r\n",
    "    above_ground = points[points[:, 2] > 0.2]\r\n",
    "\r\n",
    "    # Кластеризация\r\n",
    "    clustering = DBSCAN(eps=1.0, min_samples=5).fit(above_ground[:, :2])\r\n",
    "    labels = clustering.labels_\r\n",
    "\r\n",
    "    object_centers = []\r\n",
    "    for label in set(labels):\r\n",
    "        if label == -1:\r\n",
    "            continue\r\n",
    "        cluster = above_ground[labels == label]\r\n",
    "        center_point = cluster.mean(axis=0)\r\n",
    "        dist = np.linalg.norm(center_point[:2] - np.array([current_pos.x_val, current_pos.y_val]))\r\n",
    "        if dist < obstacle_distance_thresh:\r\n",
    "            danger_points.append(center_point)\r\n",
    "            print(f\"🚨 Обнаружено препятствие на расстоянии ~{dist:.2f} м. Остановка.\")\r\n",
    "            break\r\n",
    "        object_centers.append(center_point)\r\n",
    "\r\n",
    "    # ===== Логгирование в Rerun =====\r\n",
    "    rr.log(\"lidar/points\", rr.Points3D(points))  # Все точки\r\n",
    "    if len(object_centers):\r\n",
    "        rr.log(\"lidar/objects\", rr.Points3D(np.array(object_centers)))  # Центры объектов\r\n",
    "    if len(danger_points):\r\n",
    "        rr.log(\"lidar/danger\", rr.Points3D(np.array(danger_points), colors=np.array([[255, 0, 0]]*len(danger_points), dtype=np.uint8)))  # Опасные точки\r\n",
    "    \r\n",
    "    rr.log(\"uav/position\", rr.Transform3D(translation=(current_pos.x_val, current_pos.y_val, current_pos.z_val)))\r\n",
    "    rr.log(\"telemetry/path\", rr.LineStrips3D([path_log]))\r\n",
    "\r\n",
    "    # Сохранение данных каждую итерацию\r\n",
    "    np.save(\"lidar_points_latest.npy\", points)\r\n",
    "    np.save(\"trajectory_log.npy\", np.array(path_log))\r\n",
    "\r\n",
    "    # Остановка при опасности\r\n",
    "    if len(danger_points):\r\n",
    "        break\r\n",
    "\r\n",
    "# ===== Завершение: плавная посадка и выключение =====\r\n",
    "client.moveToPositionAsync(current_pos.x_val, current_pos.y_val, -2, 1).join()\r\n",
    "client.landAsync().join()\r\n",
    "client.armDisarm(False)\r\n",
    "\r\n",
    "# Финальное сохранение\r\n",
    "np.save(\"lidar_points_final.npy\", points)\r\n",
    "np.save(\"trajectory_final.npy\", np.array(path_log))\r\n",
    "print(\"✅ Миссия завершена. Данные сохранены.\")\r\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
